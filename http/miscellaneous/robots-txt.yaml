id: robots-txt

info:
  name: robots.txt file
  author: CasperGN,TheZakMan
  severity: info
  description: |
    It determines whether a robots.txt file is present at the root of a web server. The robots.txt file is commonly used to manage and restrict web crawlers and bots from accessing certain parts of a website. Its presence can provide insights into the site's structure, potential vulnerabilities, or areas of interest that the site owner wishes to protect or disclose.
  metadata:
    max-request: 1
  tags: miscellaneous,misc,generic

http:
  - method: GET
    path:
      - "{{BaseURL}}/robots.txt"

    host-redirects: true
    max-redirects: 2

    matchers-condition: and
    matchers:
      - type: word
        words:
          - 'User-agent:'
          - 'Disallow:'
          - 'Allow:'

      - type: word
        part: header
        words:
          - text/plain

      - type: dsl
        dsl:
          - "len(body)>=140 && status_code==200"
# digest: 4a0a00473045022100b882dbd86b40a4d6726db87db6fd979cea783db3aede48c4bd6b5a3fd1f54fc302200dc6650906f84949a42bf3ef51bcdf7517021a1d5a4d1e29470eda8783cabb63:922c64590222798bb761d5b6d8e72950
